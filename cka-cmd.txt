~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Containers-Docker
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
service docker status			### to check to status of docker engine/docker daemon

sudo service docker start			### after installation of docker, start the docker

sudo service docker enable			### to start docker at boot

~~~~~~~~~~~~~~~~~~
	Container
~~~~~~~~~~~~~~~~~~
docker info			### to check if docker is installed or not, and its information if installed

docker run nginx		### to run container image

docker ps			### to check containers running

docker rm <container id/container name>			### to remove container

docker ps -a -q			### to get only container ids in output

docker rm $(docker ps -a -q)			### to delete all containers

docker rm `sudo docker ps -a -q`			### to delete all containers

~~~~~~~~~~~~~~~
	Images 
~~~~~~~~~~~~~~~
docker images			### to check docker images available

docker images -q			### to get only docker images id

docker images | grep none | awk '{print $3}' | xargs docker rmi			### to delete none images.

docker search < application name >			### to search application images available in docker hub

docker pull <application name>			### to pull application images without running container

docker rmi <image id/ image name>			### to remove images

docker rmi $(docker images -q)			### to delete all images

docker rmi `docker images -q`			### to delete all images

~~~~~~~~~~~~~~~~~~~~~
	Build images
~~~~~~~~~~~~~~~~~~~~~
docker commit <running dockercontainerID name> < new image name>			### to create new image from current running docker
docker commit 4aab3ce3cb76 jamtur01/apache2:webserver			### to save the containers changes for future use.

docker build . -t myuser/image2			### to build from current location "Dockerfile" and tag the image

docker build . -f Dockerfile2 -t myuser/image2	// to build from "Dockerfile2" (is the name of Dockerfile),tag to upload to Docker hub



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					PODs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl run --image=nginx nginx --dry-run=client -o yaml		### display the file generated by cmd used  // generate & display POD manifest Yaml file (-o yaml). Dont create it(--dry-run)

kubectl run --image=nginx custom-nginx --port=8080		### only pod definition file is created and container port is opened //create a pod "custom-nginx" using the nginx image and expose it on container port 8080
 
kubectl run --image=httpd:alpine httpd --port=80 --expose		### service & pod is created // Create a pod called httpd using the image httpd:alpine in the default namespace. Next, create a service of type ClusterIP by the same name (httpd). The target port for the service should be 80

kubectl run --image=httpd:alpine httpd --port=80 --expose --dry-run=client -o yaml > pod-svc.yml		### pod & svc definition is created in a single file // can create pod & svc from the file 

kubectl run --image=redis redis123 --dry-run=client -o yaml > pod.yml		### generate a yaml file (pod.yaml) directly and then create pod using the file pod.yaml

kubectl create -f pod-definition.yml		### pod-definition.yml file which has information to create a pod.

kubectl get pods	### check pods created

kubectl get pods -A		### displays all pods including kube-system

kubectl get pods -l purpose=demonstrate-envars		### get pods with the help of labels; purpose=demonstrate-envars 

kubectl get pods --all-namespaces		### get pods from all namespaces

kubectl get pods --field-selector=status.phase=Running		### Get all running pods in the namespace

Kubectl get pods,svc		### get list of pods and services

kubectl get all		### get list of all 

kubectl -n kube-system get pods		### get pods from namespace kube-system

kubectl delete pod mypod	### to delete a pod "mypod"

kubectl -n default delete pods --field-selector=status.phase=Failed		### To delete pods in Failed state in namespace default

kubectl edit pod redis		### to edit/update the configuration of the running pod 'redis'

kubectl describe pod mypod	### to inspect pod

kubectl exec -it $POD_NAME bash		### to start a bash session in pods container



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					ReplicationController
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl create -f rc.yml	### create replication controller

kubectl get replicationcontroller	### check no of replication controller

kubectl get rc



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Replicaset
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl create -f replicaset-definition.yml		### create replication set

kubectl get replicaset		### check replicationset

kubectl edit rs new-replica-set		### edit virtually.

kubectle replace -f replicaset-definition.yml		### first edit "replicas" property in *.yml file to scale replication set

kubectl delete replicaset myapp-replicaset		### delete replicaset

kubectl scale replicaset new-replica-set --replicas=2		### scale replicaset "new-replica-set" without updating data in file

kubectl scale -replicas=6 -f replicaset-definintion.yml		### scale replicas by updating file & may need to apply to update



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Deployment
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl create deployment --image=nginx nginx 		### Create a deployment without yaml file

kubectl create deployment httpd-frontend --image=httpd:2.4-alpine		### create deployment without yaml file

kubectl create deployment --image=nginx nginx --dry-run=client -o yaml		### Generate and display Deployment YAML file (-o yaml). Don't create it(--dry-run)

kubectl create deployment --image=nginx nginx --replicas=4		### create Deployment with 4 Replicas

kubectl create deployment --image=nginx nginx --dry-run=client -o yaml > nginx-deployment.yaml		### Generate and save Deployment YAML file (-o yaml). Don't create it(--dry-run) , save to nginx-deployment.yaml

kubectl create -f nginx-deployment.yml		### create deployment set from existing file "nginx-deployment.yml"

kubectl scale deployment httpd-frontend --replicas=3 		### scale deployment, replicaset updated without updating file

kubectl expose deployment nginx --port 80	### to expose port 

kubectl describe deployments.apps nginx | grep -i image		### to get the image used by containers deployed by deployment "nginx"

kubectl get deployments		### to check deployments
kubectl get replicaset		### to check replicaset created by deployment
kubectl get pods	### to check pods created by deployment

kubectl get all		### to check all that has been created by deployments in one output 



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Namespace
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl create namespace dev		### create a namespace "dev"

kubectl create -f pod-definition.yml --namespace=dev		### create a pod in other namespace "dev" // or you can mentiono under metadata.

kubectl create -f pod-defintion.yml		### here namespace is mentioned in yaml file.

kubectl get namespaces		### to check the existing namespaces
kubectl get ns

kubectl get ns --no-headers | wc -l		### check counts of namespace present

kubectl get pods --namespace=kube-system		### geting pods info from kube-system namespace

kubectl get pod	-n kube-system		### short method to access from required namespaces

kubectl -n kube-system get svc		### get services from namespace "kube-system"

kubectl -n kube-system get deployment 

kubectl get pods --all-namespaces	### it will list all pods present in all namespaces.

kubectl config set-context $(kubectl config current-context) --namespace=dev		### permenently switch to other namepace "dev". if we use get cmd for pods,deployment it will show details present in "dev" namespace only.



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Services 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl expose pod redis --port=6379 --type=ClusterIP --name redis-service	### create as service redis-service to expose the redis application with the cluster on port 6379

kubectl expose deployment simple-webapp-deployment --name=webapp-service --target-port=8080 --type=NodePort --port=8080 --dry-run=client -o yaml > svc.yaml			### to generate a yaml file (svc.yaml) without creating a service

kubectl create -f svc.yaml	### to create a service using yaml file

kubectl get svc		### get the services details

kubectl describe svc kubernetes		### describes the svc "kubernetes"s

kubectl run httpd --image=httpd:alpine --port=80 --expose		### create a pod and service at the same time



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Imperative Vs Declarative
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~
	Imperative
~~~~~~~~~~~~~~~~~~~
kubectl run --image=nginx nginx		## create objects

kubectl create deployment --image=nginx nginx

kubectl expose deploymet nginx --port 80

kubectl edit deployment nginx		## update Ojects

kubectl scale deployment nginx --replicas=5

kubectl set image deployment nginx nginx=nginx:1.18

kubectl create -f nginx.yaml

kubectl replace -f nginx.yaml		### first edit the yaml file and then execute the command

kubectl replace --force -f nginx.yaml

kubectl delete -f nginx.yaml

~~~~~~~~~~~~~~~~~~~~
	Declarative
~~~~~~~~~~~~~~~~~~~~
kubectl apply -f nginx.yaml		## create Objects

kubectl apply -f /path/to/config-files		### to create multiple objects at once. if multiple yaml file are present

kubectl apply -f nginx.yaml		## update Objects



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Scheduling
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl -n kube-system get pods			### to check if the sheduler is present ### sheduler pod must be present with other pods



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Labels & Selectors
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl get node node01 --show-labels			### show all labels of node node01

kubectl get pods --show-labels			### show all labels of the existing pods

kubectl get pods -l env=dev			### to find pod with perticular label

kubectl get pods -l env=dev,bu=finance

kubectl get pods -l env=dev --no-headers | wc -l			### to count no of pods in environment "dev"

kubectl get pods --selector app=App1			## to get the pods with the help of selector



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Taints and Toleration 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl taint nodes node-name key=value:taint-effect		### syntax; NoSchedule | PreferNoSchedule | NoExecute

kubectl taint nodes node1 key1=value1:NoSchedule		### to taint on node with key-value

kubectl taint nodes node1 app=blue:NoSchedule		### to taint on node with key-value

kubectl taint nodes controlplane node-role.kubernetes.io/master:NoSchedule		### need to try this command not sure, to taint controlplane with key only.

kubectl taint nodes controlplane node-role.kubernetes.io/master:NoSchedule-		## - sign at last removes taint on node



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Node Selectors
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl label nodes <node-name> <label-key>=<label-value>			### syntax to label a node

kubectl label nodes node-1 size=Large			### label node-1 "size=Large"

kubectl get node node-1 --show-labels

kubectl label node <nodename> <labelname>-
kubectl label node node-1 size-



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Node Affinity
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl label nodes node-1 color=blue		### label the node first, and inject(add) the nodeaffinity in the pod spec of pod-definition.yaml file



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					DaemonSets
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl create -f daemonset.yml			### file same as replicaset only difference is kind, kind: DaemonSets

kubectl get ds			### to check the daemonsets present in current namespace (default)

kubectl get daemonsets --all-namespaces			### to check daemonsets in all namespaces



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Static Pods
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
docker ps		### to check static pods creation.

ps -aux | grep kubelet		### kubelete is responsible to run static pods

ps -aux | grep kubelet | grep .yaml		### copy the path of --config=/..../config.yaml

cat /..../config.yaml | grep -i staticPodPath		### get the path of pod files location.

ls /etc/kubernetes/manifests		### to list the files of pod definitions present in manifest folder.


kubectl run --restart=Never --image=busybox static-busybox --dry-run=client -o yaml --command -- sleep 1000 > /etc/kubernetes/manifests/static-busybox.yaml		### create a static pod named static-busybox that uses the busybox image ;command sleep 1000

ps -aux | grep -i "\--config"		### contains .yaml file // search --config on kubelet.

cat /var/lib/kubelet/config.yaml | grep -i staticpod		### get the static pod definition file location from the yaml file.



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Multi Scheduler
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cd /etc/kubernetes/manifests/		### to check the manifest files; kube-scheduler.yaml

cat /etc/kubernetes/manifest/kube-scheduler.yaml		### sheduclar file

kubectl get events



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Logging and Monitoring 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~
	Monitoring
~~~~~~~~~~~~~~~~~~
git clone https://github.com/kubernetes-incubator/metrics-server.git			### clone files of metrics-server from git

kubectl create â€“f deploy/1.8+/			###creating a pod "metrics-server-" in kube-system for monitoring purpose; required pods/services gets created.

kubectl top node		### monitor performance metrics of node

kubectl top pod			### monitor performance metrics of pods

watch "kubectl top node"	### to watch it live performance 

~~~~~~~~~~~~~~~~
	Logging
~~~~~~~~~~~~~~~~
kubectl create -f event-simulator.yaml			### event stimulator for logs

kubectl logs -f event-simulator-pod

kubectl logs -f event-simulator-pod event-simulator			### specify name of teh container "event-simulator" if multiple containers are present in pod

kubectl logs webapp-1 | grep -i user5			### refined/consized output for pod "webapp-1"

kubectl logs webapp-2 -c			### to check no of container present in the pod "webapp-2"

kubectl logs webapp-2 -c simple-webapp			### check logs for container "simple-webapp" of pod "webapp-2" 



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Application Lifecycle Management
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl rollout status deployment/myapp-deployment		### to check the status of roll out

kubectl rollout history deployment/myapp-deployment		### to check history

kubectl set image deployment/myapp-deployment nginx=nginx:1.9.1		### here the deployment.yaml file will not be changed, so different configuration will be there in current running pod and the file.

kubectl rollout undo deployment/myapp-deployment		### if update wont work, we can reverse the update.

kubectl describe pod ubuntu-sleeper		### check command option.

~~~~~~~~~~~~~~~~~~
	ConfigMaps
~~~~~~~~~~~~~~~~~~
kubectl create configmap webapp-color --from-literal=APP_COLOR=darkblue		### imperetive method cm "webapp-color"

kubectl create -f config-map.yaml		### create config via file

kubectl get configmaps		### to get list config maps

kubectl get cm		### to get list of configMaps

kubectl get configmaps webapp-color -o yaml		### to get the yaml file of current running config "webapp-color"

Kubectl describe configmaps db-config		### cm "db-config"

kubectl explain pods --recursive | grep envFrom -A3		### to get the format to update yaml file.


~~~~~~~~~~~~~~~~
	Secretes
~~~~~~~~~~~~~~~~
kubectl create secret generic <secret-name> --from-literal=<key>=<value>		### imperative approach, to create secret directly from command; entering direct parameters

kubectl create secret generic app-secret \
--from-literal=DB_Host=mysql \
--from-literal=DB_User=root \
--from-literal=DB_Password=paswrd

kubectl create secret generic <secret-name> --from-file=<pathToFile>			### imperative approach using file

kubectl create secret gereric app-secret --from-file=app_secret.properties		### file "app_secret.properties"

kubectl create -f secret-data.yaml		### declarative approach, to create a secret from yaml file

echo -n 'mysql' | base64		### encoding value; to convert normal text "mysql" to encoded text "bX1zcWw="; to save encoded text in secret file instead of normal plain text.

kubectl get secrets		### to get list of secrets

kubectl describe secrets		### to describe newly created secret; without displaying value

kubectl describe secrets -o yaml		### shows the yaml file; with displaying values

echo -n 'bx1zcWw=' | base64 --decode		### decoding; to convert encoded text 'bx1zcWw=' to normal plain text 'mysql'



~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
					Cluster Maintenance
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~
	Os Upgrades
~~~~~~~~~~~~~~~~~~~~
kubectl conrdon node-2		### it simply marks the node as "unschedulable" and do not terminates the existing pods; it makes sure the new pods are not created on it.

kubectl drain node-1		### existing pods are terminated from the "node-1" and recreated on another node; and "node-1" is marked as cordan and unschedulable.

kubectl uncordon node-1		### node-1 marked as uncordan to "schedule" pods.

kubectl drain node01 --ignore-daemonsets		### We cannot delete/drain DaemonSet-managed pods; so we ingnored it.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Kubernetes Software Versions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubeadm version


~~~~~~~~~~~~~~~~~~~~~~~~
	Cluster upgrade
~~~~~~~~~~~~~~~~~~~~~~~~
kubectl cluster-info

kubeadm version		### to check the current version

kubectl version --short		### to check the version in short

kubeadm upgrade plan		### to check upgrade available

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Upgrade master node
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl drain controlplane --ignore-daemonsets

apt install kubeadm=1.18.0-00
kubeadm upgrade apply v1.18.0

apt install kubelet=1.18.0-00
kubectl uncordon controlplane


~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Upgrade worker node
~~~~~~~~~~~~~~~~~~~~~~~~~~~
kubectl drain node01		## from controlplane terminal.

ssh node01
apt install kubeadm=1.18.0-00
kubeadm upgrade node
apt install kubelet=1.18.0-00
exit

kubectl uncordon node01		### from controlplane terminal
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

~~~~~~~~~~~~~~~~~~~~~~~~~~~
	Backup and restore
~~~~~~~~~~~~~~~~~~~~~~~~~~~

* Backup using builtin snapshot utility 
  $ ETCDCTL_API=3 etcdctl snapshot save snapshot01.db		### ### remember to specify --endpoints=" ",--cacert,--cert,--key  ; if running cmd on etcd which is on same master then no need apply endpoints. ##snapshotname: snapshot01.db; it is saved in pwd; specify path if required.
  $ ls		### snapshot.db ; files in pwd
  $ ETCDCTL_API=3 etcdctl snapshot status snapshot01.db

* to restore ETCD cluster
  $ service kube-apiserver stop		### stop kube-apiserver
  $ ETCDCTL_API=3 etcdctl snapshot restore snapshot01.db --data-dir /var/lib/etcd-from-backup		
  ### configure this new "--data-dir=/var/lib/etcd-from-backcup" in etcd.service
  $ cd /etc/kubernetes/manifests/
  $ vi etcd.yaml 	### volumes >hostPath >path:/varlib/etcd-from-backup
  $ systemctl daemon-reload
  $ service etcd restart
  $ service kube-apiserver start































